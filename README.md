# ğŸ“Š Data Engineering Project - [Nome do Projeto]

Este projeto foi desenvolvido para processar e analisar dados do The Movie Database(TMDB). Utiliza Apache Spark, Airflow e PostgreSQL para transformar dados brutos em insights acionÃ¡veis.

ğŸ“Œ **Principais funcionalidades**:
- Coleta de dados via API.
- Processamento com Spark e armazenamento em camadas Bronze, Silver e Gold.
- OrquestraÃ§Ã£o de pipelines com Airflow.
- VisualizaÃ§Ã£o de dados com Metabase.

## ğŸ—ï¸ Arquitetura

O projeto segue a arquitetura de Data Lakehouse, organizando os dados em trÃªs camadas:

1. **Bronze**: Dados brutos armazenados no MinIO.
2. **Silver**: Dados limpos e transformados com Spark.
3. **Gold**: Dados prontos para anÃ¡lise no PostgreSQL.

ğŸš€ **Tecnologias Utilizadas**:
- **Docker**: Gerenciamento dos serviÃ§os do projeto.
- **Apache Airflow**: OrquestraÃ§Ã£o dos pipelines de dados.
- **Apache Spark**: Processamento e transformaÃ§Ã£o dos dados.
- **PostgreSQL**: Banco de dados para armazenamento e consultas analÃ­ticas.
- **MinIO**: Armazenamento de dados como Data Lake.
- **Metabase**: VisualizaÃ§Ã£o de dados e dashboards.

### ğŸ”¥ **Diagrama**
![Arquitetura](docs/arquitetura.png)  <!-- Adicione uma imagem da arquitetura, se possÃ­vel -->
## ğŸ“‚ Estrutura de DiretÃ³rios

```
ğŸ“¦ projeto-de-engenharia-de-dados
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â”œâ”€â”€ dag_processor_manager/
â”‚   â”‚   â”œâ”€â”€ scheduler/
â”œâ”€â”€ config/
â”œâ”€â”€ data_lake/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ movie_00_10/
â”‚   â”‚   â”œâ”€â”€ movie_70_80/
â”‚   â”‚   â”œâ”€â”€ movie_80_90/
â”‚   â”‚   â”œâ”€â”€ movie_90_00/
â”‚   â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ gold/
â”œâ”€â”€ docker/
â”œâ”€â”€ env/
â”œâ”€â”€ metabase/
â”‚   â”œâ”€â”€ config/
â”œâ”€â”€ postgres/
â”‚   â”œâ”€â”€ backups/
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ jobs/
â”‚   â”œâ”€â”€ scripts/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ unit/
â””â”€â”€ README.md
```

## ğŸš€ Como Rodar o Projeto

### 1ï¸âƒ£ **PrÃ©-requisitos**
Antes de iniciar, certifique-se de ter os seguintes softwares instalados:
- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)
- [Python 3.9+](https://www.python.org/)
- [API](https://www.themoviedb.org/settings/api)

### 2ï¸âƒ£ **Passos para execuÃ§Ã£o**

Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio

Ajuste o arquivo "api.env" com o seu token de autenticaÃ§Ã£o e sua chave de acesso. 

docker-compose up -d
```

Acesse os serviÃ§os:

- Airflow: http://localhost:8080 (user: airflow, senha: airflow)
- MinIO: http://localhost:9001 (user: minioadmin, senha: minioadmin)
- Metabase: http://localhost:3000
- Jupyter http://localhost:8888


---

### **5ï¸âƒ£ Pipelines de Dados**
Descreva os principais fluxos de dados no projeto.  

```md
## âš™ï¸ Pipelines de Dados

1ï¸âƒ£ **IngestÃ£o**: Os dados sÃ£o coletados via API e armazenados no MinIO (camada Bronze).  
2ï¸âƒ£ **Processamento**: O Apache Spark processa os dados e os salva na camada Silver.  
3ï¸âƒ£ **Armazenamento**: Dados transformados sÃ£o carregados no PostgreSQL (camada Gold).  
4ï¸âƒ£ **OrquestraÃ§Ã£o**: O Airflow gerencia a execuÃ§Ã£o automÃ¡tica dos pipelines.  

ğŸ›  **Principais DAGs do Airflow**:
- `ingestao_dados.py`: Coleta os dados brutos da API.
- `processamento_spark.py`: Transforma os dados na camada Silver.
- `carga_postgres.py`: Carrega os dados finais no PostgreSQL.
```

## ğŸ“Š Exemplos de Uso

ApÃ³s rodar o pipeline, vocÃª pode consultar os dados processados no PostgreSQL:

```sql
SELECT * FROM gold.tabela_principal LIMIT 10;
```
Ou usar PySpark para carregar os dados:
```
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Projeto").getOrCreate()
df = spark.read.parquet("data_lake/gold/dataset_final.parquet")
df.show()
```

---

### **7ï¸âƒ£ ContribuiÃ§Ã£o e Contato** 

```md
## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:
1. FaÃ§a um fork do repositÃ³rio.
2. Crie uma nova branch (`git checkout -b minha-feature`).
3. Commit suas mudanÃ§as (`git commit -m "Adicionei nova feature"`).
4. Envie um pull request.
```
## ğŸ“¬ Contato
DÃºvidas ou sugestÃµes? Me encontre em:
ğŸ“§ **Email:** joathan94@yahoo.com   
ğŸ“˜ **LinkedIn:** [Joathan V Grasel](https://www.linkedin.com/in/jgrasel/)
